{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7060cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f337cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_path = \"D:/roberta/roberta_en_cased_preprocess_1\"\n",
    "path = \"D:/roberta/base\"\n",
    "preprocess_model = hub.KerasLayer(preprocess_path)    \n",
    "encoder = hub.KerasLayer(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(questions, preprocess_model, encoder):\n",
    "    \n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype = tf.string)\n",
    "    \n",
    "    encoder_inputs = preprocess_model(text_input)\n",
    "    outputs = encoder(encoder_inputs)[\"sequence_output\"] \n",
    "\n",
    "    embedding_model = tf.keras.Model(text_input, outputs)\n",
    "    embeddings = embedding_model(tf.constant(questions))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653cdc29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "questions = pd.read_excel('preprocessing_result/preprocessing_result-fasttext.xlsx')\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = questions['Preprocessed_Question']\n",
    "cognitive_level = {\"Knowledge\": 0, \"Comprehension\": 1, \"Application\": 2, \"Analysis\": 3, \"Synthesis\": 4, \"Evaluation\": 5}\n",
    "questions[\"BT LEVEL\"].replace(cognitive_level, inplace = True)\n",
    "y = questions['BT LEVEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195b49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_validated = StratifiedKFold(n_splits = 10, random_state = 0, shuffle = True)\n",
    "\n",
    "fold = 1\n",
    "\n",
    "train_accuracy = []\n",
    "train_f1_score = []\n",
    "\n",
    "test_accuracy = []\n",
    "test_f1_score = []\n",
    "\n",
    "preprocess_path = \"D:/roberta/roberta_en_cased_preprocess_1\"\n",
    "path = \"D:/roberta/base\"\n",
    "preprocess_model = hub.KerasLayer(preprocess_path)    \n",
    "encoder = hub.KerasLayer(path)\n",
    "\n",
    "\n",
    "for train_index, test_index in cross_validated.split(X,y):\n",
    "    \n",
    "    #importing libraries \n",
    "    import os\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "    seed = 0\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "     \n",
    "    import tensorflow_addons as tfa\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.callbacks import CSVLogger\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, LeakyReLU, Dropout, SpatialDropout1D\n",
    "\n",
    "    print(\"Fold :\", fold)\n",
    "    print(\"========================================\")\n",
    "    fold += 1\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index],y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    \n",
    "    X_train_roberta_base = get_embedding(X_train, preprocess_model, encoder)\n",
    "    X_test_roberta_base = get_embedding(X_test, preprocess_model, encoder)\n",
    "    \n",
    "    training_logger = CSVLogger('log/training-cv.log', separator = ',', append = False)\n",
    "    \n",
    "    \n",
    "    # defining the model\n",
    "    model = Sequential()\n",
    "    # input layer\n",
    "    model.add(Input(shape= (128, 768), name= 'embedding'))\n",
    "    # CNN-1\n",
    "    model.add(Conv1D(128, 3, activation = LeakyReLU(alpha = 0.2)))\n",
    "    # Pooling layer-1\n",
    "    model.add(MaxPooling1D())\n",
    "    # CNN-2\n",
    "    model.add(Conv1D(64, 3, activation = 'relu'))\n",
    "    # Pooling layer-2\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    # Dense layer\n",
    "    model.add(Dense(32, activation = 'tanh'))\n",
    "    #dropout layer\n",
    "    model.add(Dropout(0.3))\n",
    "    #output layer\n",
    "    model.add(Dense(6, activation ='softmax'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop()\n",
    "    model.compile(optimizer = optimizer, loss='categorical_crossentropy', metrics= ['accuracy', tfa.metrics.F1Score(6, 'weighted')])\n",
    "    \n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(X_train_roberta_base, y_train, epochs = 100, batch_size = 8, validation_data = (X_test_roberta_base, y_test),\n",
    "                                                  callbacks = [training_logger], verbose = 0)\n",
    "\n",
    "    print(\"Prediction: \")\n",
    "    print(\"=======================================\")\n",
    "    \n",
    "    log_data = pd.read_csv('log/training-cv.log', sep = ',', engine = 'python')\n",
    "    \n",
    "    best_epoch = log_data[['val_accuracy']].idxmax()\n",
    "    \n",
    "    print(\"Best Epoch: \", best_epoch + 1)\n",
    "    print(\"Best Test Accuracy: \", log_data.loc[best_epoch]['val_accuracy'])\n",
    "    print(\"Best Test F1-score: \", log_data.loc[best_epoch]['val_f1_score'])\n",
    "    \n",
    "    train_accuracy.append(log_data.loc[best_epoch]['accuracy'])\n",
    "    train_f1_score.append(log_data.loc[best_epoch]['f1_score'])\n",
    "    \n",
    "    test_accuracy.append(log_data.loc[best_epoch]['val_accuracy'])\n",
    "    test_f1_score.append(log_data.loc[best_epoch]['val_f1_score'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"===========================================\")\n",
    "print(\"Training\")\n",
    "print(\"===========================================\")\n",
    "print(\"Average Accuracy: \", np.mean(train_accuracy))\n",
    "print(\"Average F1 score: \", np.mean(train_f1_score))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"===========================================\")\n",
    "print(\"Testing\")\n",
    "print(\"===========================================\")\n",
    "print(\"Average Accuracy: \", np.mean(test_accuracy))\n",
    "print(\"Average F1 score: \", np.mean(test_f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
